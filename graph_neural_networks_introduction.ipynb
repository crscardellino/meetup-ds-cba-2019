{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"font-size:2.5em;text-align:center;\">Introducción a redes neuronales sobre grafos</h1>\n",
    "<h2 style=\"font-size:1.5em;text-align:center;\">Cristian Cardellino - FAMAFyC - UNC</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contenido\n",
    "\n",
    "1. [Introducción y motivación](#Introducción-y-motivación)\n",
    "1. [Definiciones](#Definiciones)\n",
    "1. [Tipos de redes sobre grafos](#Tipos-de-redes-sobre-grafos)\n",
    "1. [Mecanismos y tareas](#Mecanismos-y-tareas)\n",
    "1. [Aprendizaje Semi-supervisado con GCNs](#Aprendizaje-Semi-supervisado-con-GCNs)\n",
    "1. [Ejemplo: Zachary's Karate Club](#Ejemplo:-Zachary's-Karate-Club)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Credits\n",
    "\n",
    "These slides are inspired on the work by Wu et al.: [\"A comprehensive survey on graph neural networks\"](https://arxiv.org/abs/1901.00596) [1] and the article by Thomas Kipf on [Graph Convolutional Networks](https://tkipf.github.io/graph-convolutional-networks/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introducción y motivación\n",
    "\n",
    "- Muchos conjuntos de datos tienen estructuras de grafos.\n",
    "    - Redes sociales, grafos de conocimiento, World Wide Web.\n",
    "- El estado del arte en clasificación de grafos son métodos de kernel.\n",
    "- En los últimos años varios han revisado el problema de generalizar redes neuronales a las estructuras arbitrarias de los grafos.\n",
    "    - Se han encontrado aplicaciones tareas de PLN [2], visión [3], predicción de tráfico [4], sistemas de recomendación [5] o química [6].\n",
    "    - Google publicó un artículo sobre como se utilizan GNN para [detectar propiedades olfativas en las moléculas](https://ai.googleblog.com/2019/10/learning-to-smell-using-deep-learning.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Definiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grafos\n",
    "\n",
    "- Un grafo se representa por un par ordenado: $G = (V, E)$.\n",
    "    - $V$ es un conjunto de vértices o nodos.\n",
    "    - $E$ es un conjunto de aristas: $e_{ij} = (v_i, v_j) \\in E$ con  $v_i, v_j \\in V$.\n",
    "- La **vecindad de un nodo** se define como: $N(v) = \\{u \\in V | (v, u) \\in E\\}$.\n",
    "- La **matriz de adyacencia** $\\textbf{A} \\in \\mathbb{R}^{n \\times n}$ ($n = |V|$) con $A_{ij} = 1$ si $e_{ij} \\in E$ y $A_{ij} = 0$ si $e_{ij} \\not \\in E$.\n",
    "- Un grafo puede tener **atributos de nodo** $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$, donde $\\mathbf{x}_v \\in \\mathbb{R}^d$ representa el vector de atributos del nodo $v$.\n",
    "- Un grafo puede tener **atributos de aristas** $\\mathbf{X}^e \\in \\mathbb{R}^{n \\times c}$, donde $\\mathbf{x}^e_{v,u} \\in \\mathbb{R}^c$ representa el vector de la arista $(v, u)$.\n",
    "- Si el grafo es **no dirigido**, $e_{ij} \\in E \\iff e_{ji} \\in E$. En grafos dirigidos esta propiedad no es necesaria.\n",
    "- Un grafo **espacio temporal** es un grafo donde los nodos de los atributos cambian dinámicamente en el tiempo. Se define como $G^{(t)} = (\\mathbf{V}, \\mathbf{E}, \\mathbf{X}^{(t)})$ con $\\mathbf{X}^{(t)} \\in \\mathbb{R}^{n \\times d}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Red neuronal sobre grafo\n",
    "\n",
    "Sean, \n",
    "\n",
    "- $G = (V, E)$ un grafo, \n",
    "- $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ la matriz de adyacencia de $E$, \n",
    "- y $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ una matriz de características de los nodos de $V$, \n",
    "\n",
    "se define una red neuronal sobre los nodos de un grafo a aquella que produce como salida una matriz $\\mathbf{Z} \\in \\mathbb{R}^{n \\times m}$ done $m$ es la cantidad de atributos de salida de un nodo.\n",
    "\n",
    "Una capa neuronal sobre el grafo se define como una función no lineal,\n",
    "\n",
    "$$\n",
    "    H^{(l+1)} = f\\big(H^{(l)}, \\mathbf{A}\\big)\n",
    "$$\n",
    "\n",
    "que de manera tal que $H^{(0)} = \\mathbf{X}$ y $H^{(L)} = \\mathbf{Z}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tipos de redes sobre grafos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Redes recurrentes sobre grafos\n",
    "\n",
    "- Son pioneras en el uso de redes neuronales en grafos.\n",
    "- Objetivo: aprender la representación de un nodo con una arquitectura recurrente.\n",
    "- Asumen que un nodo intercambia información constantemente con sus vecinos.\n",
    "- Aplican el mismo conjunto de parámetros de manera recurrente sobre los nodos de un grafo para obtener representaciones de alto nivel.\n",
    "\n",
    "<img alt=\"RecGNN\" src=\"./img/rec-gnn.png\" style=\"width:80%;margin:auto;\"/>\n",
    "<p style=\"font-size:1.5rem;text-align:right;\">Image credits: Wu et al. [1]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Redes convolucionales sobre grafos\n",
    "\n",
    "- Generalizan la operación de convolución de una \"red\" a un grafo.\n",
    "- Generan una representación de características de un nodo $v$ mediante la agregación de sus propios atributos $\\mathbf{x}_v$ y los de sus vecions $\\mathbf{x}_u | u \\in N(v)$.\n",
    "- A diferencia de las redes recurrentes, las convolucionales apilan capas para extraer representaciones de alto nivel de los nodos.\n",
    "- Han jugado un rol primario en construir varios modelos complejos de GNNs.\n",
    "\n",
    "\n",
    "<img alt=\"ConvGNN\" src=\"./img/conv-gnn.png\" style=\"width:80%;margin:auto;\"/>\n",
    "<p style=\"font-size:1.5rem;text-align:right;\">Image credits: Wu et al. [1]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Autoencoders sobre grafos\n",
    "\n",
    "- Se utilizan como método de aprendizaje no supervisado.\n",
    "- Codifican nodos/grafos en un espacio vectorial de valores latentes.\n",
    "- Reconstrucyen la información del grafo a partir de la información codificada.\n",
    "- Utilizados para aprender embeddings de redes y distribuciones generativas de grafos.\n",
    "\n",
    "\n",
    "<img alt=\"GAE\" src=\"./img/gae.png\" style=\"width:80%;margin:auto;\"/>\n",
    "<p style=\"font-size:1.5rem;text-align:right;\">Image credits: Wu et al. [1]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Redes neuronales sobre grafos espacio temporales\n",
    "\n",
    "- Buscan aprender representaciones para grafos espacio temporales.\n",
    "- Muy utilizadas en predicción de velocidad sobre tráfico [4], anticipación de maniobras de conductores [7] o reconocimiento de acciones humanas [3].\n",
    "- Buscan considerar la dependencia espacial y temporal al mismo tiempo.\n",
    "    - Varias aplicaciones suelen integrar GNNs para caputrar la dependencia espacial junto a una RNN (o CNN) que capture la dependencia temporal.\n",
    "\n",
    "\n",
    "<img alt=\"STGNN\" src=\"./img/stgnn.png\" style=\"width:80%;margin:auto;\"/>\n",
    "<p style=\"font-size:1.5rem;text-align:right;\">Image credits: Wu et al. [1]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mecanismos y tareas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mecanismos\n",
    "\n",
    "Las redes sobre grafos pueden se aplicadas en distintos niveles en base a la tarea en cuestión. Los mecanismos para utilizarlas pueden ser los siguientes:\n",
    "\n",
    "- **Nodo**: Son tareas de regresión o clasificación de nodos. Utilizan una capa densa como salida (con posible softmax) para clasificar los nodos.\n",
    "    - E.g. analisis de sentimiento en redes sociales.\n",
    "- **Arista**: Tareas de clasificación y predicción de vínculos. Buscan encontrar conexiones entre vértices y/o peso en una arista.\n",
    "    - E.g. extracción de relaciones entre entidades.\n",
    "- **Grafo**: Tareas de clasificación sobre grafos.\n",
    "    - E.g. clasificación de grafos moleculares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tareas: Aprendizaje Semi-supervisado\n",
    "\n",
    "- En el trabajo a nivel nodo, se pueden trabajar tareas semi-supervisadas.\n",
    "- Dada una red con nodos parcialmente anotados, las redes convolucionales sobre grafos pueden aprender modelos robustos que efectivamente identifican las etiquetas de los nodos no anotados.\n",
    "\n",
    "<img alt=\"Semi-supervised GCN\" src=\"./img/conv-gnn-node-level.png\" style=\"width:80%;margin:auto;\"/>\n",
    "<p style=\"font-size:1.5rem;text-align:right;\">Image credits: Wu et al. [1]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tareas: Aprendizaje Supervisado\n",
    "\n",
    "- Con grafos anotados, se pueden entrenar modelos para predecir la clase de cierto grafo.\n",
    "- Se utiliza una combinación de redes convolucionales sobre grafos, operaciones de *pooling*, y operaciones de *readout*.\n",
    "- Con una operación sobre capas densas al final y softmax se puede obtener un framework para clasificación.\n",
    "\n",
    "<img alt=\"Supervised GCN\" src=\"./img/conv-gnn-graph-level.png\" style=\"width:80%;margin:auto;\"/>\n",
    "<p style=\"font-size:1.5rem;text-align:right;\">Image credits: Wu et al. [1]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tareas: Aprendizaje No Supervisado\n",
    "\n",
    "- Se explota la información de las aristas de manera no supervisada.\n",
    "    - Puede aplicarse mediante un autoencoder sobre grafos.\n",
    "    - Otra opción es la utilización de muestreo negativo sobre aristas existentes/no existentes.\n",
    "- Se utilizan para encontrar representaciones de redes (i.e. network embeddings) o bien para la generación de grafos (utilizadas para resolver generación de grafos moleculares)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aprendizaje Semi-supervisado con GCNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graph convolutional networks\n",
    "\n",
    "- Son un tipo particular de redes convolucionales sobre grafos diseñadas por Kipf & Welling [2].\n",
    "- Presentan un modelo bastante simple que es aplicable de manera eficiente a problemas de índole semi-supervisado (e.g. que tengan nodos parcialmente anotados).\n",
    "- Pueden pensarse como una generalización de las CNN a un grafo que no esté conectado a modo de cuadrícula.\n",
    "\n",
    "<img alt=\"GCN\" src=\"./img/conv-vs-gcn.png\" style=\"width:60%;margin:auto;\"/>\n",
    "<p style=\"font-size:1.5rem;text-align:right;\">Image credits: Wu et al. [1]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Capa convolucional\n",
    "\n",
    "Sean,\n",
    "\n",
    "- $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ una matriz de adyacencia,\n",
    "- $H^{(l)}$ una representación intermedia,\n",
    "- $W^{(l)}$ una matriz de pesos para la capa $l$,\n",
    "- $\\sigma$ una función de activación no lineal,\n",
    "\n",
    "se define una capa convolucional como,\n",
    "\n",
    "$$\n",
    "    f\\big(H^{(l)}, \\mathbf{A}\\big) = \\sigma \\big(\\mathbf{A}H^{(l)}W^{(l)}\\big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Limitaciones \n",
    "\n",
    "La capa convolucional como se define en el paso anterior tiene dos limitaciones:\n",
    "\n",
    "1. Al multiplicar por $\\mathbf{A}$ se están sumando los vectores de características de todos los nodos vecinos pero no del mismo nodo (a menos que haya nodos que se autoreferencien).\n",
    "1. Otro problema es que $\\mathbf{A}$ no está normalizada y puede cambiar la escala de los vectores de atributos (e.g. aquellos nodos con más conexiones tendrán valores mayores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Soluciones \n",
    "\n",
    "Para sobrevenir estas limitaciones, Kipf & Welling [2] propusieron las siguientes soluciones sencillas pero efectivas:\n",
    "\n",
    "1. Se fuerza el ciclo sobre los mismos nodos sumando la matriz identidad $I$, luego tenemos una operación sobre una matriz $\\mathbf{\\hat{A}} = \\mathbf{A} + I$.\n",
    "1. Se multiplica $\\mathbf{A}$ por la matriz diagonal $D$ que tiene el grado de los nodos, i.e. $|N(v_i)| = d_{i} \\in D$.\n",
    "\n",
    "En base a esto, se redefine la capa convolucional sobre nodos (GCN) de la siguiente forma:\n",
    "\n",
    "$$\n",
    "    f\\big(H^{(l)}, \\mathbf{A}\\big) = \\sigma \\Big(\\hat{D}^{-\\frac{1}{2}}\\mathbf{\\hat{A}}\\hat{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)} \\Big)\n",
    "$$\n",
    "\n",
    "donde $\\hat{D}$ es la matriz de grado de la matriz $\\mathbf{\\hat{A}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Referencias\n",
    "\n",
    "- [1] Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., & Yu, P. S. (2019). A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596.\n",
    "- [2] Kipf, T. N., & Welling, M. (2016). Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907.\n",
    "- [3] Yan, S., Xiong, Y., & Lin, D. (2018, April). Spatial temporal graph convolutional networks for skeleton-based action recognition. In Thirty-Second AAAI Conference on Artificial Intelligence.\n",
    "- [4] Li, Y., Yu, R., Shahabi, C., & Liu, Y. (2017). Diffusion convolutional recurrent neural network: Data-driven traffic forecasting. arXiv preprint arXiv:1707.01926.\n",
    "- [5] Ying, R., He, R., Chen, K., Eksombatchai, P., Hamilton, W. L., & Leskovec, J. (2018, July). Graph convolutional neural networks for web-scale recommender systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 974-983). ACM.\n",
    "- [6] Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., & Dahl, G. E. (2017, August). Neural message passing for quantum chemistry. In Proceedings of the 34th International Conference on Machine Learning-Volume 70 (pp. 1263-1272). JMLR. org.\n",
    "- [7] Jain, A., Zamir, A. R., Savarese, S., & Saxena, A. (2016). Structural-RNN: Deep learning on spatio-temporal graphs. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 5308-5317)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
